# -*- coding: utf-8 -*-
"""Face Shape.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yUOT-S3QrrBmYZWfAN7yk8IeTyL9W3bt
"""

# Import Data Science Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import shutil
import tensorflow as tf
from sklearn.model_selection import train_test_split
from PIL import Image
import seaborn as sns
from termcolor import colored
import matplotlib.pyplot as plt

# Tensorflow Libraries
from tensorflow import keras
from tensorflow.keras import layers,models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import Model
from tensorflow.keras.layers import Layer
from keras.utils import plot_model
from tensorflow.keras import optimizers

# System libraries
from pathlib import Path
import os.path

# Metrics
from sklearn.metrics import classification_report, confusion_matrix
import itertools

from google.colab import drive
drive.mount('/content/drive')

DATA_DIR = '/content/drive/MyDrive/archive/FaceShape Dataset'
TRAIN_DIR = os.path.join(DATA_DIR, '/content/drive/MyDrive/archive/FaceShape Dataset/training_set')
TEST_DIR = os.path.join(DATA_DIR, '/content/drive/MyDrive/archive/FaceShape Dataset/testing_set')

def num_of_classes(folder_dir, folder_name):
    classes = [class_name for class_name in os.listdir(TRAIN_DIR)]
    print(f'number of classes in {folder_name} folder : {len(classes)}')

num_of_classes(TRAIN_DIR, 'train')
# num_of_classes(VAL_DIR, 'validation')
num_of_classes(TEST_DIR, 'test')

classes = [class_name for class_name in os.listdir(TRAIN_DIR)]
count = []
for class_name in classes :
    count.append(len(os.listdir(os.path.join(TRAIN_DIR, class_name))))

plt.figure(figsize=(15, 4))
ax = sns.barplot(x=classes, y=count, color='navy')
plt.xticks(rotation=285)
for i in ax.containers:
    ax.bar_label(i,)
plt.title('Number of samples per label', fontsize=25, fontweight='bold')
plt.xlabel('Labels', fontsize=15)
plt.ylabel('Counts', fontsize=15)
plt.yticks(np.arange(0, 105, 10))
plt.show()

# A function to return DataFrame

def create_df(folder_path) :
    all_images = []
    for class_name in classes :
        class_path = os.path.join(folder_path, class_name)
        all_images.extend([(os.path.join(class_path, file_name), class_name) for file_name in os.listdir(class_path)])
    df = pd.DataFrame(all_images, columns=['file_path', 'label'])
    return df

train_df = create_df(TRAIN_DIR)
# validation_df = create_df(VAL_DIR)
test_df = create_df(TEST_DIR)

print(colored(f'Number of samples in train : {len(train_df)}', 'blue', attrs=['bold']))
# print(colored(f'Number of samples in validation : {len(validation_df)}', 'blue', attrs=['bold']))
print(colored(f'Number of samples test : {len(test_df)}', 'blue', attrs=['bold']

# Create a DataFrame with one Label of each category
df_unique = train_df.copy().drop_duplicates(subset=["label"]).reset_index()

# Display some pictures of the dataset
fig, axes = plt.subplots(ncols=5, figsize=(8, 7),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(df_unique.file_path[i]))
    ax.set_title(df_unique.label[i], fontsize = 12)
plt.tight_layout(pad=0.5)
plt.show()

# Train generator

train_datagen = ImageDataGenerator(
    rescale=1./255,                 # Scaled images in range 0 to 1
    rotation_range=20,              # Rorate images by factor 20 degree
    width_shift_range=0.2,          # Shift images horizontally by up to 20% of their width
    height_shift_range=0.2,         # Shift images vertically by up to 20% of their width
    zoom_range=0.1,                 # Zoom in and out images by 10%
    horizontal_flip=True,           # Allow horizontal flipping
    shear_range=0.1,                # shear images by 10% their size
    fill_mode='nearest',            # fill unlocated pixels by nearest pixel
    )

train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,             # Target data
    x_col='file_path',              # X column
    y_col='label',                  # y column
    target_size=(224, 224),         # Resize images  to
    color_mode='rgb',               # Color mode
    class_mode='categorical',       # type of model
    batch_size=32,
    shuffle=True,
    seed=42,

)

# Create DataFrames for the train and test sets using the create_df function
train_df = create_df(TRAIN_DIR)
test_df = create_df(TEST_DIR)

# Now you can proceed with your data generators
# Test generator

test_datagen = ImageDataGenerator(rescale=1./255,)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    x_col='file_path',
    y_col='label',
    target_size=(224, 224),
    class_mode='categorical',
    batch_size=32,
    seed=42,
    shuffle=False
)

pre_trained_model = MobileNetV2(
    input_shape=(224, 224, 3),            # Input image size
    include_top=False,                    # model not include top layer
    weights='imagenet',                   # weights type
    pooling='avg'                         # type of pooling layer
)

# Name of layers in MobileNetV2
for layer in pre_trained_model.layers :
    print(layer.name)

# Freeze all layers, except last layer
# The goal is to train just last layer of pre trained model

pre_trained_model.trainable = True
set_trainable = False

for layer in pre_trained_model.layers :
    if layer.name == 'block_16_expand' :
        set_trainable = True
    if set_trainable :
        layer.trainable = True
    else :
        layer.trainable = False

# Add custom layers on top of the base model
model = models.Sequential()
model.add(pre_trained_model)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(5, activation='softmax'))

plot_model(model, show_shapes=True, show_layer_names=False, dpi=200)

# Model summary
model.summary()

# Compile
model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
             loss='categorical_crossentropy',
             metrics=['accuracy'])

# Model CheckPoint
checkpoint_cb = ModelCheckpoint('MyModel.keras', save_best_only=True)

# Early Stoping
earlystop_cb = EarlyStopping(patience=10, restore_best_weights=True)

# ReduceLROnPlateau
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)

from PIL import ImageFile

# Set Pillow to load truncated images
ImageFile.LOAD_TRUNCATED_IMAGES = True
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    validation_data=test_generator,
    epochs=100,
    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr]
)

model.save('MyModel.keras')

# Convert resutl of training to a DataFrame
result_df = pd.DataFrame(history.history)
result_df.tail()

# checkpoint callback, save base model weights in "MyModel.keras".
# So, we should load it
best_model = models.load_model('MyModel.keras')

test_loss, test_acc = best_model.evaluate(test_generator)

print(colored(f'Test Loss : {round(test_loss, 3)}', 'green', attrs=['bold']))
print(colored(f'Test Accuracy : {round(test_acc, 3)}', 'green', attrs=['bold']))

# Atau dalam format HDF5
model.save('/kaggle/working/MyModel.keras')

import os

# Cek apakah file sudah tersimpan
print(os.listdir('/kaggle/working/'))

x = np.arange(len(result_df))
fig, ax = plt.subplots(3, 1, figsize=(15, 12))
#  AX0 : Loss
ax[0].plot(x, result_df.loss, label='loss', linewidth=3)
ax[0].plot(x, result_df.val_loss, label='val_loss', linewidth=2, ls='-.', c='r')
ax[0].set_title('Loss', fontsize=20)
ax[0].legend()

#  AX1 : Loss
ax[1].plot(x, result_df.accuracy, label='accuracy', linewidth=2)
ax[1].plot(x, result_df.val_accuracy, label='val_accuracy', linewidth=2, ls='-.', c='r')
ax[1].set_title('Accuracy', fontsize=20)
ax[1].legend()

#  AX2 : Loss
ax[2].plot(x, result_df.lr, label='learning_rate', linewidth=2)
ax[2].set_title('learning_rate', fontsize=20)
ax[2].set_xlabel('epochs')
ax[2].legend()


plt.sharex=True


plt.show()

def evaluate_model_performance(model, val_generator, class_labels):
    """
    Evaluate the model's performance on the validation set and print the classification report.

    Parameters:
    - model: The trained model.
    - val_generator: Validation data generator.
    - class_labels: List of class names.

    Returns:
    - report: Classification report as a string.
    """

    # Getting all the true labels for the validation set
    true_labels = val_generator.classes

    # Get the class labels (names) from the generator
    class_labels = list(val_generator.class_indices.keys())

    # To get the predicted labels, we predict using the model
    predictions = model.predict(val_generator, steps=len(val_generator))

    # Take the argmax to get the predicted class indices.
    predicted_labels = np.argmax(predictions, axis=1)

    # Extracting true labels from the validation generator
    true_labels = val_generator.classes

    # Classification report
    report = classification_report(true_labels, predicted_labels, target_names=class_labels)
    print(report)
    print('\n')

    # Define a custom colormap
    colors = ["white", "#102C42"]
    # cmap_cm = LinearSegmentedColormap.from_list("cmap_cm", colors)

    # Confusion Matrix
    cm = confusion_matrix(true_labels, predicted_labels)

    # Plotting confusion matrix using seaborn
    plt.figure(figsize=(15,10))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()

evaluate_model_performance(best_model, test_generator, classes)

from PIL import Image
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Cập nhật nhãn thực tế từ kết quả của bạn
class_labels = ['Heart', 'Oblong', 'Oval', 'Round', 'Square']

def preprocess_image(image_path):
    """
    Xử lý ảnh để phù hợp với mô hình của bạn.
    """
    # Mở ảnh từ đường dẫn
    img = Image.open(image_path)
    img = img.resize((224, 224))  # Đảm bảo kích thước phù hợp với mô hình
    img_array = np.array(img) / 255.0  # Chuẩn hóa giá trị pixel
    img_array = np.expand_dims(img_array, axis=0)  # Thêm chiều batch size
    return img_array

def predict_image(image_path, model, class_labels):
    """
    Dự đoán nhãn cho ảnh đầu vào.
    """
    img_array = preprocess_image(image_path)  # Tiền xử lý ảnh
    predictions = model.predict(img_array)  # Dự đoán
    predicted_class = np.argmax(predictions, axis=1)[0]  # Lấy lớp có xác suất cao nhất
    predicted_label = class_labels[predicted_class]  # Lấy tên lớp từ nhãn
    predicted_prob = np.max(predictions)  # Lấy xác suất của lớp dự đoán
    return predicted_label, predicted_prob

# Đường dẫn tới ảnh cần dự đoán (Cập nhật đường dẫn ảnh ở đây)
image_path = "/content/Ảnh chụp màn hình 2024-11-18 234316.png"

# Hiển thị ảnh
img = Image.open(image_path)
plt.imshow(img)
plt.axis('off')  # Tắt hiển thị trục
plt.show()


predicted_label, predicted_prob = predict_image(image_path, model, class_labels)

# In kết quả dự đoán
print(f"Dự đoán: {predicted_label} với xác suất {predicted_prob:.2f}")